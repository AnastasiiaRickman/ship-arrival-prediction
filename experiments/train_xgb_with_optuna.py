import optuna
import joblib
import numpy as np
import pandas as pd
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error, mean_squared_error

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X_train_features = np.load("artifacts/X_train_features.npy")
X_test_features = np.load("artifacts/X_test_features.npy")
y_train = np.load("artifacts/y_train.npy")
y_test = np.load("artifacts/y_test.npy")
label_scaler = joblib.load("artifacts/label_scaler.pkl")

def objective(trial):
    params = {
        "max_depth": trial.suggest_int("max_depth", 3, 9),
        "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.3),
        "n_estimators": trial.suggest_int("n_estimators", 100, 600),
        "subsample": trial.suggest_float("subsample", 0.5, 1.0),
        "colsample_bytree": trial.suggest_float("colsample_bytree", 0.5, 1.0),
        "gamma": trial.suggest_float("gamma", 0, 5),
        "reg_alpha": trial.suggest_float("reg_alpha", 0.0, 1.0),
        "reg_lambda": trial.suggest_float("reg_lambda", 0.0, 1.0),
        "objective": "reg:squarederror"
    }
    
    model = xgb.XGBRegressor(**params)
    model.fit(X_train_features, y_train)
    preds = model.predict(X_test_features)
    return mean_absolute_error(y_test, preds)

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
study = optuna.create_study(direction="minimize")
study.optimize(objective, n_trials=25)

# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
print("\n–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:")
print(study.best_params)

# –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å –∏—Å—Ç–æ—Ä–∏–µ–π –æ–±—É—á–µ–Ω–∏—è
final_model = xgb.XGBRegressor(
    **study.best_params,
    eval_metric="mae"
)

eval_set = [(X_train_features, y_train), (X_test_features, y_test)]
final_model.fit(
    X_train_features, 
    y_train,
    eval_set=eval_set,
    verbose=True
)

# –ì—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
results = final_model.evals_result()
plt.figure(figsize=(10, 5))
plt.plot(results['validation_0']['mae'], label='Train')
plt.plot(results['validation_1']['mae'], label='Validation')
plt.title('XGBoost Learning Curve')
plt.xlabel('Boosting Rounds')
plt.ylabel('MAE')
plt.legend()
plt.grid(True)
plt.savefig("artifacts/xgb_learning_curve.png")
plt.show()

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –º–µ—Ç—Ä–∏–∫–∏
y_pred = final_model.predict(X_test_features)
y_pred_original = label_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()
y_test_original = label_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()

mae = mean_absolute_error(y_test_original, y_pred_original)
rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))

print(f"\nüìä MAE: {mae:.2f}")
print(f"üìä RMSE: {rmse:.2f}")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
errors = y_test_original - y_pred_original
plt.figure(figsize=(10, 5))
sns.histplot(errors, bins=30, kde=True)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫")
plt.xlabel("–û—à–∏–±–∫–∞ (—Ñ–∞–∫—Ç - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ)")
plt.grid(True)
plt.savefig("artifacts/error_distribution.png")
plt.show()

plt.figure(figsize=(8, 8))
plt.scatter(y_test_original, y_pred_original, alpha=0.5)
plt.plot([min(y_test_original), max(y_test_original)], 
         [min(y_test_original), max(y_test_original)], 
         'r--')
plt.xlabel("–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è")
plt.ylabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
plt.title("–§–∞–∫—Ç vs –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
plt.grid(True)
plt.savefig("artifacts/actual_vs_predicted.png")
plt.show()

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
joblib.dump(final_model, "models/final_xgb_model.pkl")
print("\n‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
import pandas as pd
import seaborn as sns

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ DataFrame
trials_df = pd.DataFrame([t.params for t in study.trials])
trials_df['MAE'] = [t.value for t in study.trials]

# –ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ MAE –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
sns.pairplot(trials_df, 
             vars=['max_depth', 'learning_rate', 'n_estimators', 'MAE'],
             diag_kind='kde')
plt.savefig('artifacts/parameters_impact.png')
trials_df.to_csv('optuna_results.csv', index=False)